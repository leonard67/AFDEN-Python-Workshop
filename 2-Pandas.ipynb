{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second module introducing `pandas` in AccFin Research.\n",
    "\n",
    "`pandas` is the most useful Python library for data analysis in our research. In the second module, you will learn how to use `pandas` to handle data in tabular form. We will cover the fundamental operations needed to load data, explore it, clean it, and prepare it for further analysis. By the end, you’ll have the skills to manage real-world datasets and apply `pandas` to replicate a saminal paper.\n",
    "\n",
    "**Learning Outcomes**\n",
    "\n",
    "By completing this tutorial, you will be able to:\n",
    "\n",
    "- Create and explore *Series* and *DataFrames*, the two core data structures in `pandas`.\n",
    "\n",
    "- Import and export datasets from common formats such as CSV and Stata.\n",
    "\n",
    "- Inspect and summarize data using built-in functions.\n",
    "\n",
    "- Select, filter, and slice data to focus on what matters.\n",
    "\n",
    "- Clean and transform datasets by handling missing values, renaming columns, and changing data types.\n",
    "\n",
    "- Perform basic data analysis with sorting, grouping, and simple aggregations.\n",
    "\n",
    "- Integrate pandas workflows into larger Python projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Series object from a Python List object\n",
    "List = ['Tesla','2023','1 TESLA ROAD, AUSTIN, TX', 106_618]\n",
    "series = pd.Series(List)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Series object from a Numpy array object\n",
    "array1 = np.array(['Tesla','2023','1 TESLA ROAD, AUSTIN, TX', 106_618])\n",
    "series = pd.Series(array1)\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing a Series object\n",
    "print(series[0])\n",
    "print(series[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Series object, dict1, from a dictionary object\n",
    "dict1 = {\"CompName\":\"Tesla\", \"fyear\":2023, \"Address\": \"1 TESLA ROAD, AUSTIN, TX\", \"at\": 106_618}\n",
    "series1 = pd.Series(dict1)\n",
    "print(series1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series(['Tesla','2023','1 TESLA ROAD, AUSTIN, TX', 106_618], index=['CompName', 'fyear', 'Address', 'at'])\n",
    "print(series2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing a Series object by the Index\n",
    "print(series1[\"fyear\"])\n",
    "print(series1[\"Address\":])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between a Python list and a Pandas Series object is that:\n",
    "\n",
    "- The elements in a Series object can be indexed by a label.\n",
    "- A Series object can directly apply comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List = [1,2,3,4,5,6,7,8,9,10]\n",
    "series = pd.Series(List)\n",
    "\n",
    "print(series > 5)\n",
    "print('However, List cannot be compared to a scalar value:')\n",
    "\n",
    "try:\n",
    "    print(List > 5) #This will throw an error\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series[series > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pandas DataFrame - Basic\n",
    "The difference between a *Series* object and a *DataFrame* object is that a Series object has only one row, while a DataFrame object is a table with multiple rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from a csv file\n",
    "df = pd.read_csv('data/comp_sample.csv', parse_dates=['datadate'])\n",
    "\n",
    "# pd.read_stata('comp_sample.dta'); \n",
    "# pd.read_excel('comp_sample.xlsx'); \n",
    "# pd.read_sas('comp_sample.sas7bdat', format = 'sas7bdat', encoding=\"utf-8\")\n",
    "\n",
    "# df.to_csv('comp_sample.csv', index=False)\n",
    "# df.to_stata('comp_sample.dta', ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. DataFrame Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of columns using the `columns` attrniute\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Accessing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `.iloc` and `.loc`\n",
    "**Key Differences**\n",
    "|Feature|.loc|.iloc|\n",
    "| --- | --- | --- |\n",
    "|Selection|Label-based|Integer position-based|\n",
    "|Slicing|Inclusive|Exclusive (Python's standard slicing)|\n",
    "|Error Handling|Raises `KeyError` for invalid label|Raises `IndexError` for invalid position|\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop columns using `.drop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Filtering\n",
    "(Selecting Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1. query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.query()` method in pandas is a versatile tool for filtering DataFrame rows using string expressions. It supports a wide range of operations, allowing you to create complex queries that might be cumbersome with traditional boolean indexing. Here are some of the filtering capabilities you can achieve with `df.query()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. **Basic Comparisons**\n",
    "\n",
    "You can use comparison operators like `>`, `<`, `>=`, `<=`, `==`, and `!=` within the query string to filter data based on numeric or date-time conditions.\n",
    "\n",
    "You can also check for membership `in` a list or array, which is useful for filtering categories or groups.\n",
    "\n",
    "You can combine conditions using logical operators like `&`, `|`, and `~`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2. **String Operations**\n",
    "\n",
    "`query()` supports string methods that can be used to filter rows based on string conditions. You must use the `str` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3. **Null Checks**\n",
    "\n",
    "You can check for null (or non-null) values using `isnull()` and `notnull()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4. **Variable Substitution**\n",
    "\n",
    "You can include external variables in your query by prefixing them with an `@` symbol. This is useful for dynamic queries based on variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6. **Complex Expressions**\n",
    "\n",
    "You can use more complex expressions involving arithmetic operations, functions, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: For some operations, especially those involving string methods or checking for null values, you need to specify the query engine as `python` because the default `numexpr` engine does not support all operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5. Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep='first' (default): Marks duplicates as True except for the first occurrence.\n",
    "\n",
    "keep='last': Marks duplicates as True except for the last occurrence.\n",
    "\n",
    "keep=False: Marks all duplicates as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When removing duplicates, we have 3 options:\n",
    "- `df.drop_duplicates(subset=['gvkey','fyear'], inplace=True)` keeps the **first** occurrence of unique combinations of `gvkey` and `fyear`.\n",
    "- `df.drop_duplicates(subset=['gvkey','fyear'], keep='last', inplace=True)` keeps the **last** occurrence of unique combinations of `gvkey` and `fyear`.\n",
    "- `df.drop_duplicates(subset=['gvkey','fyear'], keep=False, inplace=True)` keeps **none** of the duplicated combinations of `gvkey` and `fyear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8. Generate Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8.1. Working with Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Format**\n",
    "\n",
    "`%Y`: Year with century as a decimal number.\n",
    "\n",
    "`%y`: Year without century as a zero-padded decimal number (00-99).\n",
    "\n",
    "`%m`: Month as a zero-padded decimal number (01-12).\n",
    "\n",
    "`%B`: Full month name (January - December).\n",
    "\n",
    "`%b`: Locale’s abbreviated month name (Jan - Dec).\n",
    "\n",
    "`%d`: Day of the month as a zero-padded decimal number (01-31).\n",
    "\n",
    "`%H`: Hour (24-hour clock) as a zero-padded decimal number (00-23).\n",
    "\n",
    "`%I`: Hour (12-hour clock) as a zero-padded decimal number (01-12).\n",
    "\n",
    "`%M`: Minute as a zero-padded decimal number (00-59).\n",
    "\n",
    "`%S`: Second as a zero-padded decimal number (00-59).\n",
    "\n",
    "`%p`: Locale’s equivalent of either AM or PM.\n",
    "\n",
    "`%A`: Locale’s full weekday name.\n",
    "\n",
    "`%a`: Locale’s abbreviated weekday name.\n",
    "\n",
    "`%c`: Locale’s appropriate date and time representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.8.2. apply() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Winsorization and Trucation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, you can use the `winsorize` function from the `scipy.stats.mstats` module\n",
    "from scipy.stats.mstats import winsorize\n",
    "df['at_w1'] = winsorize(df['at'], limits=[.01,.01], inclusive=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Aggregation\n",
    "Aggregation is one of the most common uses of groupby(), where you compute a summary statistic (or statistics) about each group. \n",
    "\n",
    "For example, you can calculate the mean, median, sum, min, and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful aggregate methods on Pandas**\n",
    "- `count()`, `.sum()`\tTotal number of items\n",
    "- `first()`, `last()`\tFirst and last item\n",
    "- `mean()`, `median()`\tMean and median\n",
    "- `min()`, `max()`\tMinimum and maximum\n",
    "- `std()`, `var()`\tStandard deviation and variance\n",
    "- `prod()`\tProduct of all items\n",
    "- `sum()`\tSum of all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Transformation\n",
    "Transformation returns a DataFrame that is the same size as the input and is useful for operations such as filling NAs within groups with a value derived from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Homework**: Try to write the following function of winsorizing by group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Filtering\n",
    "Sometimes you might want to filter the data based on the properties of the group.\n",
    "\n",
    "For example, you might keep all the firms whose total asset is always larger than 100m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Summarizing\n",
    "Using descrnie() on a groupby object to get a quick overview of the statistics for each group is also very common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5. Apply\n",
    "The apply() method lets you apply a custom function to each group. This is useful for more complex operations that require a custom aggregation or transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6. Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a good practice as it cannot tell if the previous observation is indeed for the previous year.\n",
    "\n",
    "You should add:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Append and Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Append using `pd.concat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Merge using `pd.merge()`\n",
    "Basic:\n",
    "\n",
    "pd.merge(left_Dataframe, right_Dataframe, how='inner', on=[matching variables] {OR left_on= , right_on= })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.1. One-to-one matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.2. One-to-many matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.3. Many-to-many merge\n",
    "\n",
    "CCM: merge permno to Compustat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm = pd.read_csv('data/ccm.csv', parse_dates=['LINKDT','LINKENDDT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.4. Merge using SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afden-python-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
